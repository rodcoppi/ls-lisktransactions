# Artillery Endurance Testing Configuration
# Long-duration sustained load testing for stability validation

config:
  target: "{{ $processEnvironment.LOAD_TEST_BASE_URL || 'http://localhost:3000' }}"

  # Extended timeout for long-running tests
  http:
    timeout: 45
    pool: 100
    maxSockets: 100
    keepAlive: true

  # Test phases for endurance testing
  phases:
    # Phase 1: Initial warm-up (5 minutes)
    - duration: 300
      arrivalRate: 10
      name: "Warm-up phase"

    # Phase 2: Gradual ramp-up (15 minutes)
    - duration: 900
      arrivalRate: 10
      rampTo: 100
      name: "Gradual ramp-up"

    # Phase 3: Sustained load level 1 (30 minutes)
    - duration: 1800
      arrivalRate: 100
      name: "Sustained load - Level 1"

    # Phase 4: Increase to level 2 (10 minutes)
    - duration: 600
      arrivalRate: 100
      rampTo: 200
      name: "Ramp to Level 2"

    # Phase 5: Sustained load level 2 (60 minutes)
    - duration: 3600
      arrivalRate: 200
      name: "Sustained load - Level 2 (1 hour)"

    # Phase 6: Increase to level 3 (10 minutes)
    - duration: 600
      arrivalRate: 200
      rampTo: 350
      name: "Ramp to Level 3"

    # Phase 7: Peak sustained load (90 minutes)
    - duration: 5400
      arrivalRate: 350
      name: "Peak sustained load (1.5 hours)"

    # Phase 8: Gradual cool-down (15 minutes)
    - duration: 900
      arrivalRate: 350
      rampTo: 50
      name: "Gradual cool-down"

    # Phase 9: Final monitoring (5 minutes)
    - duration: 300
      arrivalRate: 50
      name: "Final monitoring"

  # Payload for test data
  payload:
    path: "../data/endurance-test-data.csv"
    fields:
      - "testId"
      - "userId"
      - "sessionId"
      - "metricType"
      - "timestamp"
    order: sequence
    skipHeader: true

  # Default headers
  defaults:
    headers:
      Content-Type: "application/json"
      Accept: "application/json"
      User-Agent: "Artillery-Endurance/1.0"
      Connection: "keep-alive"

  # Variables for test scenarios
  variables:
    userIdRange: 10000
    metricTypes: ["cpu", "memory", "disk", "network", "response_time"]
    timeWindows: ["1h", "6h", "24h"]

  # Plugin configuration for extended monitoring
  plugins:
    metrics-by-endpoint:
      useOnlyRequestNames: true
      stripQueryString: false
    publish-metrics:
      - type: statsd
        host: "{{ $processEnvironment.STATSD_HOST || 'localhost' }}"
        port: "{{ $processEnvironment.STATSD_PORT || 8125 }}"
        prefix: "artillery.endurance"
    expect:
      outputFormat: prettyError
      reportFailuresAsErrors: true

  # Memory management for long tests
  statsInterval: 30
  maxVusers: 5000

  # Endurance test specific settings
  rateLimit: 500

# Endurance test expectations (more lenient for long duration)
expectations:
  - http.response_time.p99: 1000 # 1 second for 99th percentile
  - http.response_time.p95: 400 # 400ms for 95th percentile
  - http.response_time.median: 150 # 150ms median
  - http.codes.200: 99.5 # 99.5% success rate
  - http.codes.4xx: 0.4 # Max 0.4% client errors
  - http.codes.5xx: 0.1 # Max 0.1% server errors

# Test scenarios focused on different aspects
scenarios:
  # Core API endpoints testing
  - name: "Core APIs"
    weight: 40
    flow:
      - think: 1
      - get:
          url: "/api/health"
          name: "Health Check"
          expect:
            - statusCode: 200
            - hasProperty: "status"

      - think: 2
      - post:
          url: "/api/auth/login"
          name: "User Authentication"
          json:
            email: "user{{ $randomInt(1, userIdRange) }}@example.com"
            password: "LoadTest123!"
          capture:
            - json: "$.token"
              as: "authToken"
          expect:
            - statusCode: [200, 401]

      - think: 1
      - get:
          url: "/api/metrics?range={{ metricTypes[$randomInt(0, 4)] }}&window={{ timeWindows[$randomInt(0, 2)] }}"
          name: "Metrics Query"
          headers:
            Authorization: "Bearer {{ authToken }}"
          expect:
            - statusCode: [200, 401]
            - contentType: "application/json"

  # Real-time features testing
  - name: "Real-time Features"
    weight: 20
    flow:
      - think: 2
      - get:
          url: "/api/events?longpoll=true&timeout=10"
          name: "Long Polling"
          expect:
            - statusCode: [200, 204]

      - think: 3
      - post:
          url: "/api/events"
          name: "Event Creation"
          json:
            type: "performance_test"
            data:
              testId: "{{ testId }}"
              timestamp: "{{ $timestamp }}"
              value: "{{ $randomNumber(1, 1000) }}"
          expect:
            - statusCode: [200, 201]

  # Heavy data operations
  - name: "Data Operations"
    weight: 25
    flow:
      - think: 1
      - get:
          url: "/api/metrics?range=24h&detailed=true"
          name: "Detailed Metrics"
          expect:
            - statusCode: 200
            - responseTime: 2000 # Allow up to 2 seconds for heavy queries

      - think: 2
      - post:
          url: "/api/notifications"
          name: "Notification Creation"
          json:
            type: "alert"
            severity: "{{ ['low', 'medium', 'high'][$randomInt(0, 2)] }}"
            message: "Endurance test alert {{ $randomString() }}"
          expect:
            - statusCode: [200, 201]

  # Cache performance testing
  - name: "Cache Testing"
    weight: 15
    flow:
      # First request (cache miss)
      - get:
          url: "/api/metrics/{{ $randomInt(1, 100) }}"
          name: "Cache Miss Request"
          expect:
            - statusCode: 200

      - think: 0.5

      # Second request (cache hit)
      - get:
          url: "/api/metrics/{{ $randomInt(1, 100) }}"
          name: "Cache Hit Request"
          expect:
            - statusCode: 200
            - header: "X-Cache-Status"

# Before test setup
before:
  - log: "=== Starting Artillery Endurance Test ==="
  - log: "Target: {{ target }}"
  - log: "Total duration: ~4 hours"
  - log: "Peak arrival rate: 350 req/sec"
  - log: "Expected total requests: ~4.5M"

# After test cleanup and reporting
after:
  - log: "=== Endurance Test Completed ==="
  - log: "Check the following metrics:"
  - log: "1. Memory usage trends over time"
  - log: "2. Response time degradation"
  - log: "3. Error rate patterns"
  - log: "4. Database connection stability"
  - log: "5. Cache performance consistency"
